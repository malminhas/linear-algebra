{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5870b12-5127-4e85-9459-50d2b3b76a8f",
   "metadata": {},
   "source": [
    "# Linear Algebra Playbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce4ebbb-da37-44f4-a905-24a33f2575d4",
   "metadata": {},
   "source": [
    "<p>\n",
    "Mal Minhas, v0.2<br>\n",
    "30.12.22\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952e50ef-2d57-4bff-b705-146eb6f1c8d7",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f46da42-bb2a-4334-895d-734a20219933",
   "metadata": {},
   "source": [
    "Numerous problems in engineering and science can be described or approximated by linear relationships.  The study of linear relationship is contained in the field of **linear algebra**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26b369f-69da-445c-bc1f-e3ddbaf27d4f",
   "metadata": {},
   "source": [
    "## Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33575f9e-fae7-45d1-9656-0468684c22bd",
   "metadata": {},
   "source": [
    "The set ${\\mathbb{R}}^n$ is the set of all ùëõ-tuples of real numbers. In set notation this is ${\\mathbb{R}}^n = \\{(x_1,x_2,x_3,...,x_n):x_1,x_2,x_3,...,x_n{\\in}{\\mathbb{R}}^n\\}$. For example, the set ${\\mathbb{R}}^3$ represents the set of real triples, $({x},{y},{z})$ coordinates, in three-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53df3ea9-0792-4db4-8960-7cf17003e359",
   "metadata": {},
   "source": [
    "A vector in ${\\mathbb{R}}^n$ is an ${n}$-tuple, or point, in ${\\mathbb{R}}^n$. Vectors can be written horizontally (i.e., with the elements of the vector next to each other) in a **row vector**, or vertically (i.e., with the elements of the vector on top of each other) in a **column vector**. If the context of a vector is ambiguous, it usually means the vector is a column vector. The ${i}$-th element of a vector, ${v}$, is denoted by  ${v}_i$. The transpose of a column vector is a row vector of the same length, and the transpose of a row vector is a column vector. In mathematics, the transpose is denoted by a superscript ${T}$, or  ${v}^T$. The zero vector is the vector in ${\\mathbb{R}}^n$ containing all zeros.  The following Python code creates a row vector and a separate column vector, and shows the shape of the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "203d8ff6-db87-4a75-b090-91476e5d29ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_vector of shape (1, 5):\n",
      "[[ 1 -5  3  2  4]]\n",
      "column_vector of shape (4, 1):\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "row_vector = np.array([[1, -5, 3, 2, 4]])\n",
    "column_vector = np.array([[1], \n",
    "                          [2], \n",
    "                          [3], \n",
    "                          [4]])\n",
    "print(f'row_vector of shape {row_vector.shape}:\\n{row_vector}')\n",
    "print(f'column_vector of shape {column_vector.shape}:\\n{column_vector}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73bb8c-3e69-4a24-a145-0d42021e38e7",
   "metadata": {},
   "source": [
    "The **norm** of a vector is a measure of its length. There are many ways of defining the length of a vector depending on the metric used (i.e., the distance formula chosen). The most common is called the **$L_2$ norm**, which is computed according to the distance formula you are probably familiar with from school. The $L_2$ norm of a vector $v$ is denoted by $||{v}||_2$ and $||{v}|| = \\sqrt{{\\sum_i}{v_i^2}}$. This is sometimes also called Euclidian length and refers to the ‚Äúphysical‚Äù length of a vector in 1-D, 2-D, or 3-D space. The **$L_1$ norm**, or ‚ÄúManhattan Distance,‚Äù is computed as $||{v}||_1 = {\\sum_i}|{v_i}|$, and is named after the grid-like road structure in New York City. The **p-norm**, $L_p$, of a vector is $||{v}||_p = \\sqrt[p]{{\\sum_i}{v_i^p}}$. The **$L_\\infty$ norm**, where $p=\\infty$ is written as $||ùë£||_\\infty$.  The $L_\\infty$ norm is equal to the maximum absolute value in $v$.\n",
    "\n",
    "Here we transpose the row vector defined above into a column vector and calculate its $L_1$, $L_2$, and $L_\\infty$ norms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a42779-0450-4875-911e-5176ff9d649b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_vector of shape (5, 1):\n",
      "[[ 1]\n",
      " [-5]\n",
      " [ 3]\n",
      " [ 2]\n",
      " [ 4]]\n",
      "L_1 norm is: 15.0\n",
      "L_2 norm is: 7.4\n",
      "L_inf norm is: 5.0\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "new_vector = row_vector.T\n",
    "print(f'column_vector of shape {new_vector.shape}:\\n{new_vector}')\n",
    "norm_1 = norm(new_vector, 1)\n",
    "norm_2 = norm(new_vector, 2)\n",
    "norm_inf = norm(new_vector, np.inf)\n",
    "print(f'L_1 norm is: {norm_1:.1f}')\n",
    "print(f'L_2 norm is: {norm_2:.1f}')\n",
    "print(f'L_inf norm is: {norm_inf:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91b3dcf-4887-49ec-aea7-a6784a1e3dac",
   "metadata": {},
   "source": [
    "**Vector addition** is defined as the pairwise addition of each of the elements of the added vectors. For example, if $v$ and $w$ are vectors in ${\\mathbb{R}}^n$, then $u=v+w$ is defined as $u_i=v_i+w_i$.\n",
    "\n",
    "**Vector multiplication** can be defined in several ways depending on the context. **Scalar multiplication** of a vector is the product of a vector and a scalar (i.e., a number in ${\\mathbb{R}}^n$). Scalar multiplication is defined as the product of each element of the vector by the scalar. More specifically, if $\\alpha$ is a scalar and $v$ is a vector, then \n",
    "$u = \\alpha{v}$ is defined as $u_i = \\alpha{v_i}$. Note that this is exactly how Python implements scalar multiplication with a vector.\n",
    "\n",
    "The **dot product** of two vectors is the sum of the product of the respective elements in each vector and is denoted by $.$, and $v.{w}$ is read ‚Äúv dot w.‚Äù Therefore for $v$ and $w$ $\\in{\\mathbb{R}}^n, d=v.w$ is defined as $d = \\sum\\limits_{i=1}^n {v_i}{w_i}$. The angle between two vectors, $\\theta$, is defined by the formula:\n",
    "\n",
    "$v.w = ||v||_2||w||_2cos\\theta$\n",
    "\n",
    "The dot product is a measure of how similarly directed the two vectors are.  In the following code we are calculating the angle between two vectors using dot product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "254c6d46-2bd4-40fa-96b5-65940f53ab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angle between vectors [[10  9  3]] and [[ 2  5 12]] is [[0.97992471]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import arccos, dot\n",
    "\n",
    "v = np.array([[10, 9, 3]])\n",
    "w = np.array([[2, 5, 12]])\n",
    "theta = arccos(dot(v, w.T)/(norm(v)*norm(w)))\n",
    "print(f'angle between vectors {v} and {w} is {theta}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854c9d4e-a481-4d33-96e1-d74dbf294432",
   "metadata": {},
   "source": [
    "Finally, the **cross product** between two vectors, $v$ and $w$, is written ${v}\\times{w}$. It is defined by ${v}\\times{w} = ||v||_2||w||_2\\sin(\\theta){n}$, where $\\theta$ is the angle between the $v$ and $w$ (which can be computed from the dot product) and $n$ is a vector perpendicular to both $v$ and $w$ with unit length (i.e., the length is one). The geometric interpretation of the cross product is a vector perpendicular to both $v$ and $w$ with length equal to the area enclosed by the parallelogram created by the two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ac3295-dee9-4311-8950-049c2af419d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross product between vectors [[0 2 0]] and [[3 0 0]] is [[ 0  0 -6]]\n"
     ]
    }
   ],
   "source": [
    "v = np.array([[0, 2, 0]])\n",
    "w = np.array([[3, 0, 0]])\n",
    "print(f'cross product between vectors {v} and {w} is {np.cross(v, w)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa39e8-90f5-4b5e-a433-c37ca7228419",
   "metadata": {},
   "source": [
    "A set of vectors is said to be **linearly independent** if no vector in the set can be written as a linear combination of the other vectors in the set.  A set of vectors that is not linearly independent is linearly dependent.  In the example below, we create a new vector $x$ which is a linear combination of three other vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb493046-ac37-4923-bd5b-712215c0e674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-8 -1  4]]\n"
     ]
    }
   ],
   "source": [
    "v = np.array([[0, 3, 2]])\n",
    "w = np.array([[4, 1, 1]])\n",
    "u = np.array([[0, -2, 0]])\n",
    "x = 3*v-2*w+4*u\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d866b2-2d25-4768-be41-77631951091e",
   "metadata": {},
   "source": [
    "## Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33897028-6bfb-4509-8ab8-220340db8168",
   "metadata": {},
   "source": [
    "An ${m}\\times{n}$ matrix is a rectangular table of numbers consisting of $m$ rows and $n$ columns. The norm of a matrix can be considered as a particular kind of vector norm.  If we treat the ${m}\\times{n}$ elements of $M$ are the elements of an ${m}{n}$ dimensional vector, then you can calculate the matrix norm using the same norm function in `numpy` as that for vector.  The following code shows how this works for a 3x3 matrix $M$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6050e8e2-6570-446d-bc98-7427565c2507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix M is:\n",
      "[[ 1  7  5]\n",
      " [ 2  3  4]\n",
      " [ 5  0 -2]]\n",
      "L_2 norm of M is: 10.0\n"
     ]
    }
   ],
   "source": [
    "M = np.array([[1, 7, 5], [2, 3, 4], [5, 0, -2]])\n",
    "print(f'matrix M is:\\n{M}')\n",
    "norm_2 = norm(M, 2)\n",
    "print(f'L_2 norm of M is: {norm_2:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575d191-92af-4107-9d14-7d3219786755",
   "metadata": {},
   "source": [
    "Matrix addition and scalar multiplication for matrices work the same way as for vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774085ae-d722-40c1-8714-c1db7d5c4e20",
   "metadata": {},
   "source": [
    "**Matrix multiplication** between two matrices, $P$ and $Q$, is defined when $P$ is an ${m}\\times{p}$ matrix and $Q$ is a ${p}\\times{n}$ matrix. The result of $M=PQ$ is a matrix $M$ that is ${m}\\times{n}$. The dimension with size $p$ is called the _inner matrix_ dimension, and the inner matrix dimensions must match for matrix multiplication to be defined. The dimensions $m$ and $n$ are called the _outer matrix_ dimensions. Formally, if $P$ is ${m}\\times{p}$ and $Q$ is ${p}\\times{n}$, then $M=PQ$ is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1e776d-b509-48bb-9a73-6f880a9f6301",
   "metadata": {},
   "source": [
    "$M_{ij} = \\sum\\limits_{p=1}^nP_{ik}Q_{kj}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c284c-fadd-4301-81d0-9a0a1da36e74",
   "metadata": {},
   "source": [
    "The product of two matrices $P$ and $Q$ in Python is achieved by using the `dot` method in `numpy`. The transpose of a matrix is a reversal of its rows with its columns. The transpose is denoted by a superscript, $T$, such as $MT$ is the transpose of matrix $M$. In Python, the method `T` for an `numpy` `array` is used to get the transpose. For example, if $M$ is a matrix, then $M.T$ is its transpose.  The following code shows how to compute $M$, the matrix product of $P$ an $Q$ as well as $M^T$, the transpose of $M$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef6e90aa-929d-41c0-97c9-188cf656621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix P is:\n",
      "[[1 7]\n",
      " [2 3]\n",
      " [5 0]]\n",
      "matrix Q is:\n",
      "[[2 6 3 1]\n",
      " [1 2 3 4]]\n",
      "matrix M=PQ is:\n",
      "[[ 9 20 24 29]\n",
      " [ 7 18 15 14]\n",
      " [10 30 15  5]]\n",
      "transpose of M is:\n",
      "[[ 9  7 10]\n",
      " [20 18 30]\n",
      " [24 15 15]\n",
      " [29 14  5]]\n"
     ]
    }
   ],
   "source": [
    "P = np.array([[1, 7], [2, 3], [5, 0]])\n",
    "Q = np.array([[2, 6, 3, 1], [1, 2, 3, 4]])\n",
    "print(f'matrix P is:\\n{P}')\n",
    "print(f'matrix Q is:\\n{Q}')\n",
    "print(f'matrix M=PQ is:\\n{np.dot(P, Q)}')\n",
    "print(f'transpose of M is:\\n{np.dot(P, Q).T}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b51d52-391a-41ce-a416-732884b394d4",
   "metadata": {},
   "source": [
    "A **square matrix** is an ${n}\\times{n}$ matrix; that is, it has the same number of rows as columns. The **determinant** is an important property of square matrices. The determinant is denoted by $det(M)$, both in mathematics and in the `numpy` `linalg` package, sometimes it is also denoted as $|M|$.  In the case of a 2√ó2 matrix, the determinant is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d883938-7362-4d5b-a2bf-62a51c29df37",
   "metadata": {},
   "source": [
    "$|M| = \\begin{bmatrix}a & b\\\\c & d\\end{bmatrix} = ad - bc$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44741eb6-54a4-4a17-b6ef-011cfb45ad94",
   "metadata": {},
   "source": [
    "In the case of a 3x3 matrix, the determinant is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f0f765-4bcf-4aa0-9926-f07c12bfe6da",
   "metadata": {},
   "source": [
    "$|M| = \\begin{bmatrix}a & b & c\\\\d & e & f\\\\g & h & i\\end{bmatrix} = aei + bfg + cdh - ceg - bdi -afh$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69440b2-5f37-49a1-a38c-58ffce9c6d8f",
   "metadata": {},
   "source": [
    "The **identity matrix** is a square matrix with ones on the diagonal and zeros elsewhere. The identity matrix is usually denoted by ùêº, and is analagous to the real number identity, 1. That is, multiplying any matrix by ùêº (of compatible size) will produce the same matrix.  The following code outlines how to calculate a determinant and identity matrix using `numpy.linalg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1efc47-de43-4930-a386-79f352b61cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix M is:\n",
      "[[0 2 1 3]\n",
      " [3 2 8 1]\n",
      " [1 0 0 3]\n",
      " [0 3 2 1]]\n",
      "determinant |M| is: -38.0\n",
      "identity matrix I:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "MI:\n",
      "[[0. 2. 1. 3.]\n",
      " [3. 2. 8. 1.]\n",
      " [1. 0. 0. 3.]\n",
      " [0. 3. 2. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import det\n",
    "\n",
    "M = np.array([[0,2,1,3], \n",
    "             [3,2,8,1], \n",
    "             [1,0,0,3],\n",
    "             [0,3,2,1]])\n",
    "print(f'matrix M is:\\n{M}')\n",
    "print(f'determinant |M| is: {det(M):.1f}')\n",
    "I = np.eye(4)\n",
    "print(f'identity matrix I:\\n{I}')\n",
    "print(f'MI:\\n{np.dot(M, I)}')\n",
    "assert((np.dot(M, I) == M).all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f23d95f-98e7-4f5d-9329-98317ab98d07",
   "metadata": {},
   "source": [
    "The **inverse** of a square matrix $M$ is a matrix of the same size, $N$, such that $M.N=I$. The inverse of a matrix is analagous to the inverse of real numbers. For example, the inverse of 3 is 13 because (3)(13)=1. A matrix is said to be invertible if it has an inverse. The inverse of a matrix is unique so, for an invertible matrix, there is only one inverse for that matrix. If $M$ is a square matrix, its inverse is denoted by $M^{-1}$ in mathematics, and it can be computed in Python using `numpy.linalg.inv`.  Here is an example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d176ff6-8208-445e-a8a1-b6d73ad69b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix M is:\n",
      "[[0 2 1 3]\n",
      " [3 2 8 1]\n",
      " [1 0 0 3]\n",
      " [0 3 2 1]]\n",
      "inverse of M:\n",
      "[[-1.57894737 -0.07894737  1.23684211  1.10526316]\n",
      " [-0.63157895 -0.13157895  0.39473684  0.84210526]\n",
      " [ 0.68421053  0.18421053 -0.55263158 -0.57894737]\n",
      " [ 0.52631579  0.02631579 -0.07894737 -0.36842105]]\n",
      "M.inv(M):\n",
      "[[ 1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [ 0. -0.  1. -0.]\n",
      " [ 0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "print(f'matrix M is:\\n{M}')\n",
    "print(f'inverse of M:\\n{inv(M)}')\n",
    "print(f'M.inv(M):\\n{np.round(np.dot(inv(M), M))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c9fac-a3c3-47c9-84c7-c6e2073b14d7",
   "metadata": {},
   "source": [
    "For a 2√ó2 matrix, the analytic solution of the matrix inverse is:\n",
    "\n",
    "$M^{-1} = \\begin{bmatrix}a & b\\\\c & d\\end{bmatrix}^{-1} = \\frac{1}{|M|}\\begin{bmatrix}d & -b\\\\-c & a\\end{bmatrix}$\n",
    "\n",
    "The calculation of the matrix inverse for the analytic solution becomes complicated with increasing matrix dimension.  The process of doing so is broadly the same as learning how to solve a system of linear equations.  There are many other methods can make things easier, such as Gaussian elimination, Newton‚Äôs method and Eigendecomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db0e8d-fb02-4461-aa03-b598c8bbf29c",
   "metadata": {},
   "source": [
    "There are matrices that do not have inverses. These matrices are called **singular**. Matrices that do have an inverse are called **nonsingular**.  One way to determine if a matrix is singular is by computing its determinant. If the determinant is 0, then the matrix is singular; if not, the matrix is nonsingular.  Here is an example of a singular matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1df158ba-16fb-4fcd-b7fe-887a375264e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\n",
      " [[0 1 0]\n",
      " [0 0 0]\n",
      " [1 0 1]]\n",
      "det(P):\n",
      " 0.0\n"
     ]
    }
   ],
   "source": [
    "P = np.array([[0,1,0],\n",
    "              [0,0,0],\n",
    "              [1,0,1]])\n",
    "print('P:\\n', P)\n",
    "print('det(P):\\n', det(P))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5192c4e6-8efc-4a45-8695-a0eda899fa71",
   "metadata": {},
   "source": [
    "A matrix that is close to being singular (i.e., the determinant is close to 0) is called ill-conditioned. Although ill-conditioned matrices have inverses, they are problematic numerically in the same way that dividing a number by a very, very small number is problematic. The **condition number** is a measure of how ill-conditioned a matrix is, and it can be computed using Numpy‚Äôs function cond from linalg. The higher the condition number, the closer the matrix is to being singular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0735265-5656-4594-98b4-3494cb3a1c95",
   "metadata": {},
   "source": [
    "The **rank** of an ${m}\\times{n}$ matrix ùê¥ is the number of linearly independent columns or rows of $A$, and is denoted by $rank(A)$. It can be shown that the number of linearly independent rows is always equal to the number of linearly independent columns for any matrix.  A matrix is called full rank if $rank(A)=min(m,n)$. The matrix, $A$, is also full rank if all of its columns are linearly independent. An **augmented matrix** is a matrix, $A$, concatenated with a vector, $y$, and is written $[A,y]$. This is commonly read ‚Äú$A$ augmented with $y$.‚Äù  You can use `np.concatenate` to concatenate the two. If $rank([A,y])=rank(A)+1$, then the vector, $y$, is ‚Äúnew‚Äù information. That is, it cannot be created as a linear combination of the columns in $A$. The rank is an important property of matrices because of its relationship to solutions of linear equations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4a51d0-36b5-40d2-9363-1aa83f0043ba",
   "metadata": {},
   "source": [
    "Here matrix $A=[[1,1,0],[0,1,0],[1,0,1]]$.  We compute the condition number and rank for this matrix and for $y=[[1],[2],[1]]$, we get the augmented matrix $[A, y]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb066d53-72aa-4230-8bc5-11798b3c9829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix A is:\n",
      "[[1 1 0]\n",
      " [0 1 0]\n",
      " [1 0 1]]\n",
      "Condition number: 4.048917339522305\n",
      "Rank: 3\n",
      "vector y is:\n",
      "[[1]\n",
      " [2]\n",
      " [1]]\n",
      "Augmented matrix [A,y] is:\n",
      "[[1 1 0 1]\n",
      " [0 1 0 2]\n",
      " [1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import cond, matrix_rank\n",
    "\n",
    "A = np.array([[1,1,0],\n",
    "              [0,1,0],\n",
    "              [1,0,1]])\n",
    "\n",
    "print(f'matrix A is:\\n{A}')\n",
    "print(f'Condition number: {cond(A)}')\n",
    "print(f'Rank: {matrix_rank(A)}')\n",
    "y = np.array([[1], [2], [1]])\n",
    "print(f'vector y is:\\n{y}')\n",
    "A_y = np.concatenate((A, y), axis = 1)\n",
    "print(f'Augmented matrix [A,y] is:\\n{A_y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20530f9-babd-497b-a9bd-639bd4c14bed",
   "metadata": {},
   "source": [
    "## Linear Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232a9eb3-0fef-4069-b261-450e5a631426",
   "metadata": {},
   "source": [
    "For vectors $x$ and $y$, and scalars $a$ and $b$, it is sufficient to say that a function, $F$, is a **linear transformation** if\n",
    "\n",
    "$F(ax+by) = aF(x) + bF(y)$\n",
    "\n",
    "It can be shown that multiplying an ${m}\\times{n}$ matrix, $A$, and an  ${n}\\times{1}$ vector, $v$, of compatible size is a linear transformation of $v$. Therefore from this point forward, a matrix will be synonymous with a linear transformation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d23481-0bf1-4ff0-9338-73874458d3be",
   "metadata": {},
   "source": [
    "A **system of linear equations** is a set of linear equations that share the same variables.  They can therefore be converted to a **matrix form** of ${Ax = y}$ where $A$ is an ${m}\\times{n}$ matrix, $A(i,j)=a_{i,j}$, $y$ is a vector in ${\\mathbb{R}}^n$, and $x$ is an unknown vector in ${\\mathbb{R}}^n$.  Here is an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eecf2f8-34f2-4e3d-ac77-f3d31fb68158",
   "metadata": {},
   "source": [
    "$\\begin{aligned}\n",
    "4x + 3y -5z = 2\\\\\n",
    "-2x - 4y +5z = 5\\\\\n",
    "7x + 8y = 3\\\\\n",
    "x + 2z = -1\\\\\n",
    "9x + y - 6z = 6\n",
    "\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e1f88e-a644-4e73-bad6-78a8fe1d0a4d",
   "metadata": {},
   "source": [
    "$\\begin{bmatrix}4 & 3 & -5\\\\-2 & -4 & 5\\\\7 & 8 & 0\\\\1 & 0 & 2\\\\9 & 1 & -6\\end{bmatrix}\n",
    "\\begin{bmatrix}x\\\\y\\\\z\\end{bmatrix} = \n",
    "\\begin{bmatrix}2\\\\5\\\\3\\\\-1\\\\6\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dca8c51-f533-4080-857b-c524b836601c",
   "metadata": {},
   "source": [
    "Given a system of linear equations in matrix form, $Ax=y$, where $A$ is an ${m}\\times{n}$ matrix, this means there are $m$ equations and $n$ unknowns in our system. A solution to a system of linear equations is an $x$ in ${\\mathbb{R}}^n$ that satisfies the matrix form equation. Depending on the values that populate $A$ and $y$, there are three distinct solution possibilities for $x$:\n",
    "* **Case 1**: There is no solution for $x$. If $rank([A,y]) = rank(A) + 1$, then $y$ is linearly independent from the columns of $A$.\n",
    "* **Case 2**: There is a unique solution for $x$. If $rank([A,y]) = rank(A)$, then $y$ can be written as a linear combination of the columns of $A$ and there is at least one solution for the matrix equation. For there to be only one solution, $rank(A) = n$ must also be true. \n",
    "* **Case 3**: There is an infinite number of solutions for $x$. If $rank([A,y]) = rank(A)$, then $y$ is in the range of $A$, and there is at least one solution for the matrix equation. However, if $rank(A) < n$, then there is an infinite number of solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68923d29-28be-462f-92cc-23622c133f3c",
   "metadata": {},
   "source": [
    "There are a number of methods that have been developed to solve a systems of linear equations by hand when there is a unique solution. Some of the common methods include:\n",
    "* The **Gauss Elimination method** turns a matrix $A$ into an upper triangular form to solve the system of equations.\n",
    "* The **Gauss-Jordan Elimination method** solves the systems of equations using a procedure to turn $A$ into a diagonal form.\n",
    "* The **LU decomposition method** aims to turn $A$ into the multiple of two matrices $L$ and $U$, where $L$ is a lower triangular matrix while $U$ is an upper triangular matrix.\n",
    "* The **Gauss-Seidel Method** is a specific iterative method, that start with an initial guess of the solution and then repeatedly improves the solution until the change of the solution is below a threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c8756f-5192-48a7-acd4-9b319a138a5a",
   "metadata": {},
   "source": [
    "It's easy to solve a linear equations where there is one solution using `numpy.linalg` as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a18023f4-1049-4244-975a-3e6c7df91ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix A of shape (m,n) = (3, 3) is:\n",
      "[[ 4  3 -5]\n",
      " [-2 -4  5]\n",
      " [ 8  8  0]]\n",
      "vector y is:\n",
      "[[ 2]\n",
      " [ 5]\n",
      " [-3]]\n",
      "Augmented matrix [A,y] is:\n",
      "[[ 4  3 -5  2]\n",
      " [-2 -4  5  5]\n",
      " [ 8  8  0 -3]]\n",
      "Rank [A,y]: 3\n",
      "Rank A: 3\n",
      "Rank A == Rank [A,y] == n so there is one unique solution\n",
      "[[ 2.20833333]\n",
      " [-2.58333333]\n",
      " [-0.18333333]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[4, 3, -5], \n",
    "              [-2, -4, 5], \n",
    "              [8, 8, 0]]\n",
    "            )\n",
    "y = np.array([[2, 5, -3]]).T\n",
    "print(f'matrix A of shape (m,n) = {A.shape} is:\\n{A}')\n",
    "print(f'vector y is:\\n{y}')\n",
    "A_y = np.concatenate((A, y), axis = 1)\n",
    "print(f'Augmented matrix [A,y] is:\\n{A_y}')\n",
    "print(f'Rank [A,y]: {matrix_rank(A_y)}')\n",
    "print(f'Rank A: {matrix_rank(A)}')\n",
    "print(f'Rank A == Rank [A,y] == n so there is one unique solution')\n",
    "x = np.linalg.solve(A, y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624a5e55-becf-43c4-9c4f-61942861d761",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bdd1d4-6d8e-4c6c-9343-585ad334af6c",
   "metadata": {},
   "source": [
    "* Linear algebra is the foundation of many engineering fields.\n",
    "* Vectors can be considered as points in ${\\mathbb{R}}^n$; addition and multiplication are defined on them, although not necessarily the same as for scalars.\n",
    "* A set of vectors is linearly independent if none of the vectors can be written as a linear combination of the others.\n",
    "* Matrices are tables of numbers. They have several important properties including the determinant, rank, and inverse.\n",
    "* A system of linear equations can be represented by the matrix equation $Ax = y$.\n",
    "* The number of solutions to a system of linear equations is related to the rank(ùê¥) and the $rank([A,y])$. It can be zero, one, or infinity.\n",
    "* We can solve the equations using Gauss Elimination, Gauss-Jordan Elimination, LU decomposition and Gauss-Seidel method.\n",
    "* Methods exist to find matrix inversion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
